

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Weekly Digest 8 &mdash; MTH 448/548  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  
    <link rel="canonical" href="https://www.mth548.org/Digests/digest_8.html" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Week 9 (4/4-4/10)" href="../Schedule/week_9.html" />
    <link rel="prev" title="Week 8 (3/28-4/3)" href="../Schedule/week_8.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../master.html" class="icon icon-home"> MTH 448/548
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Logistics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">MTH 448/548 Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../to_do.html">Current Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../report_guide.html">Project Report Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../useful_links.html">Useful links</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Schedule</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_0.html">Preliminaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_1.html">Week 1 (1/31-2/6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_2.html">Week 2 (2/7-2/13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_3.html">Week 3 (2/14-2/20)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_4.html">Week 4 (2/21-2/27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_5.html">Week 5 (2/28-3/6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_6.html">Week 6 (3/7-3/13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_7.html">Week 7 (3/14-3/20)</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../Schedule/week_8.html">Week 8 (3/28-4/3)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#Notebook">Notebook</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../Schedule/week_8.html#Weekly-digest">Weekly digest</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Weekly Digest 8</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#Project">Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#Data-formats">Data formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#lxml-installation">lxml installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#Resources">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Schedule/week_8.html#Exercise">Exercise</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_9.html">Week 9 (4/4-4/10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_10.html">Week 10 (4/11-4/17)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_11.html">Week 11 (4/18-4/24)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Schedule/week_12.html">Week 12 (4/25-5/1)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Tools/Numpy/numpy_toc.html">Numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/Pandas/pandas_toc.html">Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/Seaborn/seaborn_toc.html">Seaborn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/Plotly/plotly_toc.html">Plotly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/requests/requests.html">Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/beautiful_soup/beautiful_soup.html">Beautiful Soup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/json/json.html">JSON</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools/Regex/regex_toc.html">Regular expressions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Projects/mnist_with_knn/mnist_with_knn.html">Project: Recognizing digits with k-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/mnist_with_k_means/mnist_with_k_means.html">Project: MNIST with k-means</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/baby_names/baby_names.html">Project: Baby names</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/scrapping_marathon_results/scrapping_marathon_results.html">Project: Scrapping marathon results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/discord_logs/discord_logs.html">Project: Discord logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/kde_marathon_results/kde_marathon_results.html">Project: Analysis of marathon results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Projects/text_with_naive_bayes/text_with_naive_bayes.html">Project: Text classification with naive Bayes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../master.html">MTH 448/548</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../master.html">MTH 448/548</a> &raquo;</li>
        
          <li><a href="../Schedule/week_8.html">Week 8 (3/28-4/3)</a> &raquo;</li>
        
      <li>Weekly Digest 8</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="weekly-digest-8">
<h1>Weekly Digest 8<a class="headerlink" href="#weekly-digest-8" title="Permalink to this headline">Â¶</a></h1>
<p><strong>linggan asks:</strong></p>
<blockquote>
<div><p>Why is beautiful soup called beautiful soup?</p>
</div></blockquote>
<p>It refers to the âsoupâ of HTML or XML tags that it processes.
It is also a reference to a song in the book âAliceâs Adventures in Wonderlandâ
by Lewis Carroll.</p>
<p><strong>Saiful asks:</strong></p>
<blockquote>
<div><p>Can you please suggest some resources to learn web scrapping?</p>
</div></blockquote>
<p>It you search the web for âweb scrappping with Pythonâ you will get see a lot of
results. I have had a look at some, and they looked useful. There is even a book
âWeb Scraping with Pythonâ published by OâReilly. The best way to learn web scrapping
is to practice with some webpages.</p>
<p><strong>Metin asks:</strong></p>
<blockquote>
<div><p>I have very little understanding of how the world wide web works (despite nearly using it
to breathe at this point) so please excuse the questions below.</p>
<p>1. Could you give us some additional examples of websites (besides Wikipedia) that would deny
a request coming from Pythonâs requests if the user agent is not identified?</p>
<p>2. Are there any websites that only accept requests from a predetermined set of user agents
(that is, for which there is a list of approved possible user agents and the request gets
denied if it does not use an agent from that list)?</p>
</div></blockquote>
<p>This should anwer both questions. Amazon.com routinely blocks requests it recognizes as coming
from scripts. In particular, it will block a request if the user-agent is not one that is associated
with some commonly used web browser. To circumvent it, people scapping amazon pages set
their user-agent to the user-agent of some browser, effectively pretending that their script is
a web browser. There are many web pages that list user-agents of various web browsers, here is
<a class="reference external" href="https://developers.whatismybrowser.com/useragents/explore/">an example</a>.</p>
<p>Faking a user-agent for scrapping amazon may work in a short term, but after a few requests
the script can still get blocked if amazon servers notice that too many requests are coming from
the same IP address. Then there are ways around it, e.g. by using proxy servers.</p>
<p><strong>Scott asks:</strong></p>
<blockquote>
<div><p>I was wondering if there is a way to save variables in python or jupyter like you can in MATLAB.</p>
</div></blockquote>
<p>In Jupyter notebook you can use <a class="reference external" href="https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-save">%save</a>
magic. For more general applications, saving variables and their value to e.g. to a json file
is a good option.</p>
<p><strong>Griffin asks:</strong></p>
<blockquote>
<div><p>Will we be using web scrapping with a more data analytical approach in a future project?</p>
</div></blockquote>
<p>We be will using the marathon data (that you were scrapping for project 4) for some analysis.</p>
<p><strong>Mikhael asks:</strong></p>
<blockquote>
<div><p>Can you explain User-header again in class just as review?</p>
</div></blockquote>
<p>You can have a look <a class="reference external" href="https://www.mth548.org/Tools/requests/requests.html#User-Agent">here</a>.
You can also search the web for âuser-agent web scrappingâ. There are many pages that
explain what user-agent is and how to use it.</p>
<p><strong>Ninghui asks:</strong></p>
<blockquote>
<div><p>Every website can be turn to API form or just specific website has API. Does json have
any limitation?</p>
</div></blockquote>
<p>Some websites/web services have API, some donât. As for JSON, it depends what you mean by
a limitation. For example, JSON stores data as text, which may require more space than some
other data storage formats. On the other hand, text can be read by humans, text files are easy
to transfer between computers etc. Thus what from one point of view is a limitation, from
a different perspective is a useful feature.</p>
<p><strong>Steven asks:</strong></p>
<blockquote>
<div><p>Will there be web scrapping in the future projects?</p>
</div></blockquote>
<p>No, we will move on to different topics.</p>
<p><strong>Luca asks:</strong></p>
<blockquote>
<div><p>What is the best format to handle a huge data set?</p>
</div></blockquote>
<p>It depends on the kind of data. For some data types, a database of some kind may be a good solution.
For truly large sets of data, the problem will be not just the data format but the hardware needed to
store and handle the data. In such cases, you may consider using one of the commercial data warehouses
such as Google BigQuery, Amazon RedShift, Microsoft Azure Data Lake etc. These services use specialized
servers, specifically designed to store and process very large amounts of data.</p>
<p><strong>felix asks:</strong></p>
<blockquote>
<div><p>How are real enterprise-scale web crawlers (like pagerank etc) implemented?
Presumably they donât use python.</p>
</div></blockquote>
<p>PageRank is an algorithm for ranking webpages, not a web crawler. Google, Microsoft etc.
use proprietary software for crawling the web, I am not sure how much of their source
code they make public. It is possible to write a fully-featured web crawler using Python,
see e.g. <a class="reference external" href="https://scrapy.org/">Scrapy</a>.</p>
<p><strong>Haiyi asks:</strong></p>
<blockquote>
<div><p>For me, I find it difficult to use the information of the web page to draw pictures, and many times
I donât know how to determine where the information I want is on the web page.</p>
</div></blockquote>
<p>I am not sure what is the question here.</p>
<p><strong>David asks:</strong></p>
<blockquote>
<div><p>Will we learn about other web scraping libraries?</p>
</div></blockquote>
<p>No, we will be moving on to different topics.</p>
<p><strong>Cassandra asks:</strong></p>
<blockquote>
<div><p>Is there a faster way to scrap data from a website than what we did
in class or is that the most efficient way to get data?</p>
</div></blockquote>
<p>In general, scrapping a webpage will will follow a similar process
to the one we went over in class.</p>
<p><strong>John asks:</strong></p>
<blockquote>
<div><p>Are we going to have a final project that combines a little bit
of everything we learned this semester?</p>
</div></blockquote>
<p>No, a project using all tools covered in this course would be just too long.</p>
<p><strong>Dakota asks:</strong></p>
<blockquote>
<div><p>How many projects do we have left in semester?</p>
</div></blockquote>
<p>We should have time for 3-4 more.</p>
<p><strong>Netra asks:</strong></p>
<blockquote>
<div><p>Are we going to create our own webpage for a project?</p>
</div></blockquote>
<p>No, this is not related to the main subject of this course which is data analysis.</p>
<p><strong>Bochun asks:</strong></p>
<blockquote>
<div><p>Iâm confused about the project distribution. This project is a short project that
only need code. So Iâm kind of confused about the report organization and code documentation.
What kind of comment of the code is necessary? I found it difficult to describe what does
each lines do, because if someone complete know nothing about coding, my comments wonât help him
understand the codes. And someone who do know about coding, especially python, will not need
that amount of comment.</p>
</div></blockquote>
<p>There should be enough code documentation to be useful to someone who knows Python.
This does not have to be much, but brief explanation what various pieced of code are
doing are helpful. In general, tt is a good practice to document code even if you
are the only person that will use it.</p>
<p><strong>Farhat asks:</strong></p>
<blockquote>
<div><p>Could beautifulsoup work with a PDF file?</p>
</div></blockquote>
<p>No, PDF format is entirely different than HTML/XML, and much less pleasant to work with.
There are other Python libraries though for processing PDF files.</p>
<p><strong>Jason asks:</strong></p>
<blockquote>
<div><blockquote>
<div><p>Will we have a project where we utilize XML/Json files?</p>
</div></blockquote>
<p>Working with XML files is similar to working with HTML files which was
the subject of project 4. You will be working with JSON for the next project.</p>
</div></blockquote>
<p><strong>Michael asks:</strong></p>
<blockquote>
<div><p>Is there a way for website to prevent outside users from scrapping data?</p>
</div></blockquote>
<p>There is no way to prevent scrapping entirely, but there are ways to make it more difficult.
This is for example what all the websites using <a class="reference external" href="http://www.captcha.net/">captchas</a> are doing.</p>
<p><strong>Adrian asks:</strong></p>
<blockquote>
<div><p>Will we learn how to automate certain tasks throughout the semester ?</p>
</div></blockquote>
<p>This is essentially what we are doing most of the time in this course. Instead of manually
editing Excel worksheets you can use pandas, instead of copying and pasting data from the web
pages you can scrap them using request and BeautifulSoup etc.</p>
<p><strong>Meaghan asks:</strong></p>
<blockquote>
<div><p>Should we expect to be working with a lot of excel/csv files in the next coming projects?</p>
</div></blockquote>
<p>There will be csv files used, but not a lot of them.</p>
<p><strong>Thinh asks:</strong></p>
<blockquote>
<div><p>Is there any competitive library which support the scrapping such as BeautifulSoup?
Also, is there any security issue when scrapping a certain website?</p>
</div></blockquote>
<p>As for BeautifulSoup compatitors, there are several e.g. Scrapy or lxml.
I donât think that basic web scrapping brings any special security issues.</p>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Schedule/week_9.html" class="btn btn-neutral float-right" title="Week 9 (4/4-4/10)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../Schedule/week_8.html" class="btn btn-neutral float-left" title="Week 8 (3/28-4/3)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="width: 100px; border-width:0" src="https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-sa.svg" /></a>  <a href="mailto:admin@mth548.org">Bernard Badzioch</a>
      <span class="lastupdated"><br/>
        Last updated on Apr 23, 2022.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-161474487-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>